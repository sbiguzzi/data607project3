---
title: "Project 3 - Data Science Skills"
author: "Arora, Arushi; Biguzzi, Stefano; Costello, Ian; Fernandes, Peter; Tapke, Jordan"
date: "10/7/2020"
output:
  html_document:
    includes:
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = 'hide')
```

# Loading Libraries
```{r, message=FALSE}
library(tidyverse)
library(RCurl)
library(sjmisc)
library(reshape2)
library(DescTools)
library(httr)
library(tm)
library(ngram)
library(RMariaDB)
```

# Creating the SQL Database
```{r}
# #Create connection to database
# con <- dbConnect(RMariaDB::MariaDB(),
#                  dbname = 'datascienceskills',
#                  user = Sys.getenv("userid"), 
#                  password = Sys.getenv("pwd"), 
#                  host = '34.123.100.43')
```
```{r}
# # data frames of skills and jobs
# jobs1_df <- read.csv(url("https://raw.githubusercontent.com/jtapke/School-Projects/master/Project%203/jobs1.csv"))
# jobs2_df <- read.csv(url("https://raw.githubusercontent.com/jtapke/School-Projects/master/Project%203/jobs2.csv"))
# jobs3_df <- read.csv(url("https://raw.githubusercontent.com/jtapke/School-Projects/master/Project%203/jobs3.csv"))
# skills_df <- read.csv(url("https://raw.githubusercontent.com/sbiguzzi/data607project3/main/skill_word_count_v2.csv"))


# Write to tables in database

# dbWriteTable(con, name = "jobs1", value = jobs1_df, overwrite = TRUE)
# dbWriteTable(con, name = "jobs2", value = jobs2_df, overwrite = TRUE)
# dbWriteTable(con, name = "jobs3", value = jobs3_df, overwrite = TRUE)
# dbWriteTable(con, name = "skills", value = skills_df, overwrite = TRUE)
```

# Loading Data from SQL Database
```{r, results='hide',warning=FALSE}
#Create connection to database
con <- dbConnect(RMariaDB::MariaDB(),
                 dbname = 'datascienceskills',
                 user = Sys.getenv("userid"),
                 password = Sys.getenv("pwd"),
                 host = '34.123.100.43')

#Load skill list
skills <- dbReadTable(conn = con, "skills")

#Load data science job posts data set 1
DS.1 <- dbReadTable(conn = con, "jobs1")
DS.1 <- DS.1 %>%
  select("Job.Title","Company.Name","Location","Job.Description","Salary.Estimate","Sector")

#Load data science job posts data set 2
DS.2 <- dbReadTable(conn = con, "jobs2")
DS.2 <- DS.2 %>%
  select(-reviews)

#Load data science job posts dataset 3
DS.3 <- dbReadTable(conn = con, "jobs3")
DS.3 <- DS.3 %>%
  select(job_title,company_name,inferred_city,inferred_state,job_description,job_type,salary_offered,category)
```

# Cleaning Data Frame {.tabset .tabset-fade}
After loading the data we wanted to make the jobs data frames all have the same columns so we could combine them into on table. This way when we wanted to grab the skills from the job description it would only have to hit off of one table and not three.

## Jobs data frame 1
```{r}
#Modify DS.1 columns for appending
names(DS.1) <- c("job_title","company_name","location","job_description","salary","sector")

#Create necessary columns
DS.1$city <- str_split(DS.1$location,", ",simplify = TRUE)[,1] #city
DS.1$state <- str_split(DS.1$location,", ",simplify = TRUE)[,2] #state
DS.1$state <- gsub("United Kingdom","UK",DS.1$state) #state abbr
DS.1$company_name <- gsub("[\n].*","",DS.1$company_name) #company name
DS.1$job_type <- NA #job type
DS.1$job_id <- paste0("DS.1_",1:nrow(DS.1)) #job id
DS.1$salary <- gsub("\\(([^\\)]+)\\)","",gsub(" ","",DS.1$salary)) #salary
DS.1$salary <-
  with(DS.1, replace(salary, salary == "$10-$26PerHour", "$20K-$54K"))
DS.1$salary <-
  with(DS.1, replace(salary, salary == "$17-$27PerHour", "$35K-$56K"))
DS.1$salary <-
  with(DS.1, replace(salary, salary == "$34-$53PerHour", "$70K-$110"))

#Drop unused columns
DS.1 <- DS.1 %>% select(-location)
```

## Jobs data frame 2
```{r}
#Rename DS.2 columns for appending
names(DS.2) <- c("job_title","company_name","job_description","location")

#Create necessary columns
DS.2$city <- str_split(DS.2$location,", ",simplify = TRUE)[,1] #city
DS.2$state <- gsub(".*,\\s([A-Z]{2}).*","\\1",DS.2$location)
DS.2$job_type <- NA #job type
DS.2$salary <- NA #salary
DS.2$sector <- NA #sector
DS.2$job_id <- paste0("DS.2_",1:nrow(DS.2)) #job id

#Drop unused columns
DS.2 <- DS.2 %>% select(-location)
```

## Jobs data frame 3
```{r}
#Rename DS.2 columns for appending
names(DS.3) <- c("job_title","company_name","city","state","job_description","job_type","salary","sector")

#Change state names to abbr
DS.3$state <- setNames(state.abb, toupper(state.name))[toupper(DS.3$state)]

#Create necessary columns
DS.3$job_id <- paste0("DS.3_",1:nrow(DS.3))
```

## Creating final jobs data frame
```{r}
#Append data sets together into one large job description data frame
final.DS.df <- rbind(rbind(DS.1,DS.2),DS.3)

#Remove leading and trailing whitespaces
for(i in names(final.DS.df)){
  final.DS.df[[i]] <- trimws(
      final.DS.df[[i]],
      which = c("both"),
      whitespace = "[ \t\r\n]"
    )
}

#Remove R element after use
rm(i)
```

# Cleaning final jobs data frame

The next step was to clean the `job_description` column to make it easier when matching the skills data frame to the final jobs data frame.

## Creating function and using Regex
```{r}
#Create function to clean up string
clean.string <- function(x){
  x <-tolower(x)
  x <-removeWords(x,c(stopwords('en'),"without","various","sexual","high",
                      "color","race","part","will","work","skills","years",
                      "including","strong","using","qualifications","role",
                      "field","experience","also","highly","qualified","like",
                      "areas","good","job","new","use","can","one","big","may",
                      "able"))
  x <-removePunctuation(x)
  x <-stripWhitespace(x)
  x <- removeNumbers(x)
  return(x)}

#Replace job_description with cleaned version
final.DS.df$job_description <-
  clean.string(final.DS.df$job_description)

#Replace punctuation and non alphabet characters
final.DS.df$job_description <- gsub("[[:punct:]]|[^[:alnum:]]"," ", final.DS.df$job_description)

#Replace short words
final.DS.df$job_description <- gsub("*\\b[[:alpha:]]{1,2}\\b *"," ", final.DS.df$job_description)

#Replace any word that look like websites
final.DS.df$job_description <- gsub("(f|ht)tp(s?)\\w+"," ", final.DS.df$job_description)
final.DS.df$job_description <- gsub("(www)\\w+"," ", final.DS.df$job_description)

#Trim white space again
final.DS.df$job_description <- trimws(final.DS.df$job_description,which='both',whitespace="[ ]")

#Remove all white space between words
final.DS.df$job_description <-
  gsub("[ ]","",final.DS.df$job_description)
```

# Creating the final skills data frame

We wanted to create a simplified data frame with just the `job_id` and the `job_description` columns to use as the base data frame to search each skill word in. We then ran it through a loop were for each skill in the `skill` column of the skills data frame we searched for each row of the `job_description` column contained that string. The loop would then spit out the DS.skills data frame with `job_id`,`job_description`, and `skill` columns, where `skill` is a concatenated version of all the skills found. Finally, we transformed the final skills data frame to long format and added additional detail from `final.DS.df`.

## Create simplified job data frame
```{r}
#Create simplified dataset
DS.skills <- final.DS.df[,c("job_id","job_description")]

#Initiate Skills column in simplified dataset
DS.skills$skill <- NA
```

## Match skills within job description
```{r}
#Loop to populate skills column
for (row in 1:nrow(DS.skills)){
  skill.list <- list()
  for (i in skills$skill){
    if (str_contains(DS.skills$job_description[row],i)){
      skill.list <- append(skill.list,i)
      DS.skills$skill[row] <- paste(skill.list,collapse = ", ")
    }
  }
}

#Remove R element after use
rm(row,i)
```

## Split the skill column from concatenated to long format
```{r}
#Create final data frame with list of skills and job_id
final.DS.skills <- filter(DS.skills,(!is.na(skill)))

#Split string on comma
col.length <- max(sapply(strsplit(final.DS.skills$skill, ", "),length)) 

#Setting max columns and creating one column per skill
final.DS.skills <-
  data.frame(cbind(final.DS.skills$job_id,str_split_fixed(final.DS.skills$skill, ", ",n=col.length))) 

#Renaming columns
names(final.DS.skills) <- c("job_id",paste0("skill",1:col.length)) 

#Converting data frame to long format
final.DS.skills <- final.DS.skills %>% 
  gather(SkillNum, skill, skill1:paste0("skill",col.length)) %>% 
  filter(!(is.na(skill))) %>%
  select(-SkillNum)

#Remove R element after use
rm(col.length)
```

## Add additional detail to the final skills data frame
```{r}
#Add some additional job details job state and job salary
final.DS.skills <- merge(final.DS.skills,final.DS.df[,c("job_id","salary","state")],by="job_id")

#Add skill details type and skillname
final.DS.skills <- merge(final.DS.skills,skills[,c("skill","type","skillname")],by="skill")

#Replace blanks with NA
final.DS.skills[final.DS.skills==""] <- NA

#Reordering data frame and resetting index
final.DS.skills <- final.DS.skills[order(final.DS.skills$job_id),]
rownames(final.DS.skills) <- NULL
```

# Analysis

After getting the final data science skills data frame we created different tables for different counts. The first one was the top 20 skills that jobs posts are asking for as shown by how many jobs are asking for that skill. The second count was to see the top type of skills that jobs are asking for as seen by the number of jobs requesting the different type of skills.

## Create the skill count table
```{r}
#Create final data science skill count
final.skill.count <- as.data.frame(final.DS.skills %>%
  group_by(skillname,type) %>%
  tally(sort = TRUE) %>%
  head(20))

#Add percent of total jobs
final.skill.count <- final.skill.count %>%
  mutate(pct_total = round(n/nrow(DS.skills),4))
```

## Create the skill type count table
```{r}
#Get final counts of jobs vs type of skill
final.type.count <- 
  as.data.frame(unique(final.DS.skills[,c("type","job_id")]) %>%
  group_by(type) %>%
  tally(sort = TRUE) %>%
  head(20)) %>%
  mutate(pct_jobs = round(n/nrow(DS.skills),4))
```

# Results

In the following graph we see that the most requested skill type is tool. This skill type is for skills like python, R, SQL. With 94.75% jobs asking for some type of programming tool to be accepted for the job. The second highest skill type was the hard skill set, which includes things like data mining, research, regression. 91.26% jobs asked that candidates are familiar with at least one type of hard skill. And the final skill type that jobs are asking for is the soft skill set, which include communication and collaboration. These types of skills were requested by 81.86% of job posts.
```{r, echo=F, fig.show='asis'}
ggplot(data=final.type.count, aes(x=reorder(type, -n), y=n, fill=type)) +
  #allows for Y value to be variable instead of "count"
    geom_bar(stat="identity")+
  #color palette
  scale_fill_brewer(palette="Paired")+
  #changes labels of axis
    xlab("Type of Skill") + ylab("# of jobs requesting skills") +
  #creates title for graph
    ggtitle("Most Requested Type of Skills")+
  #removes legend
    guides(fill=FALSE)+
  #zooms in on data points to better see if there are differences
    coord_cartesian(ylim = c(10000,20000))
```

Digging a little deeper we see that the most requested skill for all jobs, with 61.64% of jobs asking, is python. It is interesting to see that for 20,873 jobs, 5 of the top 10 skills are tools, 3 are hard skills and only 2 are soft skills.
```{r, echo=F, fig.show='asis'}
skills.plot <- final.skill.count[1:10,]
ggplot(data=skills.plot, aes(x=reorder(skillname, -n), y=n, fill=skillname)) +
  #allows for Y value to be variable instead of "count"
    geom_bar(stat="identity")+
  #color palette
  scale_fill_brewer(palette="Paired")+
  #changes labels of axis
    xlab("Skill") + ylab("# of jobs requesting skills") +
  #rotate x labels 90 degrees
  theme(axis.text.x = element_text(angle = 90))+
  #creates title for graph
    ggtitle("Most Vaulable Data Science Skills")+
  #removes legend
    guides(fill=FALSE)+
  #zooms in on data points to better see if there are differences
    coord_cartesian(ylim = c(3000,13000))
```

# Conclusion

Our findings suggest that the jobs are primarily asking for hard skills and tools and then soft skills. We would like to critique the suggestion that there is no need to focus on soft skills as much as focusing heavily on hard skills and tools because that can affect the communication of data with your audience. We believe this focus on hard skills and tools in the job descriptions is due to Data Science being an emerging field and so data scientists must be generalists. Just as in the early days of modern chemistry, chemists had to be decent lab technicians, so too much data scientist be equally proficient in coding as well as statistics.


***

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>